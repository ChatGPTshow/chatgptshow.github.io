"use strict";(self.webpackChunkchatgpt_blog=self.webpackChunkchatgpt_blog||[]).push([[4704],{4056:(p,l,e)=>{e.r(l),e.d(l,{comp:()=>i,data:()=>t});var o=e(641);const a={href:"https://www.gptclaude.top/",target:"_blank",rel:"noopener noreferrer"},n={href:"https://mp.weixin.qq.com/s/muGMyr_zD55Y4Tb2ranj-A",target:"_blank",rel:"noopener noreferrer"},s={},i=(0,e(6262).A)(s,[["render",function(p,l){const e=(0,o.g2)("ExternalLinkIcon");return(0,o.uX)(),(0,o.CE)("div",null,[l[4]||(l[4]=(0,o.Fv)('<h1 id="claude-opus-4-6-vs-gpt-5-3-codex-主要更新了什么-有哪些不同-如何使用呢" tabindex="-1"><a class="header-anchor" href="#claude-opus-4-6-vs-gpt-5-3-codex-主要更新了什么-有哪些不同-如何使用呢"><span>Claude Opus 4.6 vs GPT-5.3-Codex，主要更新了什么？有哪些不同？如何使用呢？</span></a></h1><p>快过年了，最近国内AI老热闹了，元宝送红包，千问送奶茶，火药味十足，运营更是一套一套的，再看看国外，人家直接双双上模型，给新年打了一手双响炮。</p><p><img src="https://picx.zhimg.com/v2-3afa54767ca2036449bdd223697f4301_1440w.jpg" alt=""></p><p>Anthropic 刚把 <strong>Claude Opus 4.6</strong> 端上来， OpenAI 转头就甩出 <strong>GPT-5.3-Codex</strong>，而且 Codex 不是“PPT 发布”，在 App、CLI、IDE 插件里已经能直接用。</p><p>更关键的是，这两次更新都不是那种</p><blockquote><p>“参数 +1%，大家散了吧”</p></blockquote><p>而是<strong>路线非常清晰的强化</strong>：</p><ul><li><p>Claude 继续往「<strong>通用智能、长上下文、复杂思考</strong>」走</p></li><li><p>Codex 则彻底站在「<strong>代码、工程、智能体执行力</strong>」这一边</p></li></ul><p>如果你平时：</p><ul><li>要写代码</li><li>要写文档</li><li>要做分析</li><li>或者已经在用 Agent 搭工作流</li></ul><p>那这次更新，<strong>大概率会影响你接下来怎么用模型</strong>。</p><p>所以问题来了： <strong>Claude Opus 4.6 和 GPT-5.3-Codex，到底各自升级了什么？又有什么本质不同？</strong></p><blockquote><p>以下均为官方数据</p><p>👉<strong>文末附带获取方法</strong></p></blockquote><h2 id="一、claude-opus-4-6" tabindex="-1"><a class="header-anchor" href="#一、claude-opus-4-6"><span>一、Claude Opus 4.6</span></a></h2><p>如果用一句话形容 Claude Opus 4.6： <strong>它不是变得更激进了，而是更稳了。</strong></p><p><img src="https://pic4.zhimg.com/v2-8e58c770baad0163d0f6b9200cefe2a7_1440w.jpg" alt=""></p><h3 id="长上下文-终于拉到-opus-该有的位置" tabindex="-1"><a class="header-anchor" href="#长上下文-终于拉到-opus-该有的位置"><span>长上下文，终于拉到 Opus 该有的位置</span></a></h3><p>这次 Anthropic 做了一件很关键的事： <strong>第一次把 Opus 系列推到了 100 万 token 上下文（测试版）</strong>。</p><ul><li>常规可用：200K token</li><li>测试版：100 万 token</li><li>最大输出：128K token（相比上一代 64K 翻倍）</li></ul><p>这在很多场景下意味着什么？</p><p>不是“我可以塞更多废话”， 而是：</p><ul><li>一整个代码仓库</li><li>一整份研究资料</li><li>多轮、长时间不间断的对话</li></ul><p><strong>可以一次性放进模型的工作记忆里。</strong></p><p>在 MRCR v2 八针 1M（大海捞针）测试中，Opus 4.6 比 Sonnet 4.5 整整高出了 <strong>57 分</strong></p><p><img src="https://pic1.zhimg.com/v2-d978856aa2746d81831e7a0335e68538_1440w.jpg" alt=""></p><p>这个提升非常直观地体现在：</p><blockquote><p>你不需要频繁帮它“回忆上下文”。</p></blockquote><h3 id="自适应思考-开始学会-该不该多想" tabindex="-1"><a class="header-anchor" href="#自适应思考-开始学会-该不该多想"><span>自适应思考，开始学会“该不该多想”</span></a></h3><p>Opus 4.6 这次引入了 <strong>Adaptive Thinking（自适应思考）</strong>。</p><p><img src="https://pic3.zhimg.com/v2-53e2103648854fad5a0c95dde3cc5a38_1440w.jpg" alt=""></p><p>简单说就是：</p><ul><li>简单问题 → 不强行长推理</li><li>复杂问题 → 自动加深思考</li><li>高级用户 → 可以把 effort 拉到 max</li></ul><p>这是一个非常 Claude 风格的更新。 它不追求“每次都想得很复杂”， 而是<strong>在合适的时候，认真想一想</strong>。</p><h3 id="长对话不崩-上下文自动压缩" tabindex="-1"><a class="header-anchor" href="#长对话不崩-上下文自动压缩"><span>长对话不崩，上下文自动压缩</span></a></h3><p>还有一个很容易被忽略，但实际非常好用的功能： <strong>上下文压缩（beta）</strong>。</p><p>当对话或 Agent 任务快要打到上下文上限时，Claude 会自动把早期内容压缩成摘要，再用摘要继续对话。</p><p>结果就是： <strong>你可以把对话拉得非常长，但模型依然“记得发生过什么”。</strong></p><h3 id="claude-in-powerpoint" tabindex="-1"><a class="header-anchor" href="#claude-in-powerpoint"><span>Claude in PowerPoint</span></a></h3><p>本次更新Claude也集成到了PowerPoint侧边栏中，让它在创建新内容之前读取现有的布局、字体和母版。</p><p>Claude可以根据客户模板构建演示文稿、对现有幻灯片进行针对性编辑。</p><p><img src="https://pic2.zhimg.com/v2-344cb5dd39bf5dee7146844a4579883f_1440w.jpg" alt=""></p><p>你会明显感觉到： <strong>Claude Opus 4.6 更像一个“不会情绪化输出的同事”。</strong></p><h3 id="价格方面" tabindex="-1"><a class="header-anchor" href="#价格方面"><span>价格方面</span></a></h3><p>在价格方面，API价格保持不变，还是＄5/$25每百万token（输入/输出）。</p><p>如果是超过20万token的上下文，这里会有额外定价，是$10/$37.50每百万token。</p><p><img src="https://pic4.zhimg.com/v2-4cc0d28d40842bfbacad83634474a81d_1440w.jpg" alt=""></p><h3 id="适合什么人用" tabindex="-1"><a class="header-anchor" href="#适合什么人用"><span>适合什么人用？</span></a></h3><p>如果你主要在做：</p><ul><li>长文写作</li><li>产品方案、研究分析</li><li>多轮复杂对话</li><li>对表达准确性要求很高的任务</li></ul><p>那 Claude Opus 4.6 非常对路。</p><p>一句话总结：</p><blockquote><p><strong>Claude Opus 4.6 更像一个耐心、克制、逻辑感很强的合作者。</strong></p></blockquote><h2 id="二、gpt-5-3-codex-这是给程序员准备的版本" tabindex="-1"><a class="header-anchor" href="#二、gpt-5-3-codex-这是给程序员准备的版本"><span>二、GPT-5.3-Codex：这是给程序员准备的版本</span></a></h2><p>和 Claude 的“稳”不同， GPT-5.3-Codex 的气质只有一个字：<strong>干。</strong></p><p><img src="https://pic4.zhimg.com/v2-1efdb0bb79fcb24e1edcc6a25cffd401_1440w.jpg" alt=""></p><h3 id="不只是写代码-而是理解-工程" tabindex="-1"><a class="header-anchor" href="#不只是写代码-而是理解-工程"><span>不只是写代码，而是理解“工程”</span></a></h3><p><img src="https://pica.zhimg.com/v2-7d0cc6277c15fb63cb3cd0cf6e16f3ee_1440w.jpg" alt=""></p><p>GPT-5.3-Codex 融合了：</p><ul><li>GPT-5.2-Codex 的编码能力</li><li>GPT-5.2 的推理能力和专业知识</li></ul><p>结果是一个非常明确的变化：</p><ul><li>以前：能写函数</li><li>现在：开始理解项目结构、多文件关系、真实工作流</li></ul><p>再加上 <strong>整体推理速度提升 25%</strong> ，Codex 已经很适合被长期放在 IDE 或 CLI 里“盯活”。</p><h3 id="osworld-verified-一个非常夸张的指标" tabindex="-1"><a class="header-anchor" href="#osworld-verified-一个非常夸张的指标"><span>OSWorld-Verified：一个非常夸张的指标</span></a></h3><p>GPT-5.3-Codex 有一个指标高得有点离谱： <strong>OSWorld-Verified（视觉桌面操作）</strong></p><p><img src="https://pic2.zhimg.com/v2-d194d31dcaeca469d73ced51fb246c5d_1440w.jpg" alt=""></p><p>简单说，就是让 AI：</p><ul><li>看屏幕截图</li><li>操作真实的电脑界面</li><li>完成桌面级任务</li></ul><p>成绩是：</p><ul><li>人类基准：72%</li><li>GPT-5.2-Codex：38.2%</li><li>GPT-5.2：37.9%</li><li><strong>GPT-5.3-Codex：64.7%</strong></li></ul><p>这说明一件事： <strong>Codex 已经不只是“写代码”，而是开始“动手做事”。</strong></p><h3 id="真实工程评测依然强" tabindex="-1"><a class="header-anchor" href="#真实工程评测依然强"><span>真实工程评测依然强</span></a></h3><p>在<strong>目前最接近程序员真实工作方式的评测之一</strong>的Terminal-Bench 2.0测试（终端编程，在真实终端环境里完成编程任务）中，<strong>两家唯一可正面对比的指标</strong>上：</p><ul><li>GPT-5.3-Codex 比 Claude Opus 4.6 高 <strong>12 分</strong></li></ul><p>而在GPT其他版本模型下，GPT-5.3-Codex 相比</p><ul><li>相比 GPT-5.2-Codex，高了13.3 个点</li><li>相比通用 GPT-5.2，高了15.1 个点</li></ul><p><img src="https://pic3.zhimg.com/v2-fa8f5fa622408df2492ce20bda2635cc_1440w.jpg" alt=""></p><p>在纯工程场景下，Codex 的优势非常清晰！！！代码方面直接碾压其他模型</p><h3 id="codex-现在更适合做什么" tabindex="-1"><a class="header-anchor" href="#codex-现在更适合做什么"><span>Codex 现在更适合做什么？</span></a></h3><p>如果你的痛点是：</p><ul><li>日常开发节奏太慢</li><li>旧代码难读、难改</li><li>想快速搭 demo / PoC</li><li>学新语言或新框架</li></ul><p>那 GPT-5.3-Codex 的目标很明确：</p><blockquote><p><strong>减少你真正敲代码的时间</strong></p></blockquote><h2 id="三、差异一览" tabindex="-1"><a class="header-anchor" href="#三、差异一览"><span>三、差异一览</span></a></h2><p>这里不站队，只说事实。</p><ul><li><p><strong>定位</strong></p><ul><li>Claude：通用智能、复杂思考</li><li>Codex：代码、工程、智能体执行</li></ul></li><li><p><strong>风格</strong></p><ul><li>Claude：克制、严谨、稳定</li><li>Codex：高效、直接、行动派</li></ul></li><li><p><strong>输出重点</strong></p><ul><li>Claude：解释、分析、结构化思考</li><li>Codex：可执行代码、工具调用、任务完成</li></ul></li><li><p><strong>适合人群</strong></p><ul><li>Claude：内容、产品、研究、分析</li><li>Codex：工程、开发、自动化</li></ul></li></ul><p>结论很简单： <strong>不是谁更强，而是谁更适合你的场景。</strong></p><h2 id="四、普通用户该怎么用" tabindex="-1"><a class="header-anchor" href="#四、普通用户该怎么用"><span>四、普通用户该怎么用？</span></a></h2><h3 id="最简单的选择法" tabindex="-1"><a class="header-anchor" href="#最简单的选择法"><span>最简单的选择法</span></a></h3><ul><li>主要写代码 → <strong>GPT-5.3-Codex</strong></li><li>主要写方案 / 长文 / 分析 → <strong>Claude Opus 4.6</strong></li><li>两种都干 → <strong>分工协作</strong></li></ul><h3 id="一个很实用的-组合拳" tabindex="-1"><a class="header-anchor" href="#一个很实用的-组合拳"><span>一个很实用的“组合拳”</span></a></h3><p>很多人已经在这么用：</p><ol><li><p>用 <strong>Claude Opus 4.6</strong></p><ul><li>梳理需求</li><li>写设计说明</li><li>明确约束条件</li></ul></li><li><p>用 <strong>GPT-5.3-Codex</strong></p><ul><li>实现代码</li><li>修改多文件</li><li>Debug、重构</li></ul></li><li><p>再回到 <strong>Claude</strong></p><ul><li>写文档</li><li>做总结</li><li>给出可读解释</li></ul></li></ol><p>这套流程，<strong>非常容易提升整体效率</strong>。</p><h3 id="如何使用到它们呢" tabindex="-1"><a class="header-anchor" href="#如何使用到它们呢"><span>如何使用到它们呢？</span></a></h3><p>Claude Opus 4.6、GPT-5.3-Codex这些都可以通过升级原有账号的形式进行使用到</p>',95)),(0,o.Lk)("blockquote",null,[(0,o.Lk)("p",null,[l[1]||(l[1]=(0,o.eW)("可以前往我们的自助代充导航网站：",-1)),(0,o.Lk)("a",a,[l[0]||(l[0]=(0,o.eW)("gptclaude.top",-1)),(0,o.bF)(e)])]),l[2]||(l[2]=(0,o.Lk)("p",null,"(复制到浏览器打开)",-1))]),l[5]||(l[5]=(0,o.Fv)('<p><img src="https://pica.zhimg.com/v2-9399e1696bf59f7d6b509cf00bc27fe8_1440w.jpg" alt=""></p><p>目前 <strong>Claude Code</strong> 更新最新版本可以直接使用到Opus 4.6，下面那个1M context是更长的上下文，但这也代表了更多的消耗。</p><p><img src="https://pic2.zhimg.com/v2-4be80df78e2a33dbfb21d9305f0e4c43_1440w.jpg" alt=""></p><p>而 <strong>GPT-5.3-Codex</strong>，目前还没有API，不过在app，CLI，IDE插件and网页版都能用了，有小伙伴反馈说更新后没有看到，如果没有发现5.3-codex的可以重新登录一下获取模型，或者手动修改配置文件<code>config.toml</code>，像这样</p><p><img src="https://picx.zhimg.com/v2-e4d31ca32e62d9f629a8a803700eb2b9_1440w.jpg" alt=""></p><p>如果是vscode插件的话，更新重启之后就可以看到啦~</p><p><img src="https://pic1.zhimg.com/v2-3c2d702a7bca9588b779b061f3037c98_1440w.jpg" alt=""></p><p>如果你只用于这些编程模型，不是很想升级的话，这里推荐我自己也在用的中转站，可以使用到Claude code、Codex、Gemini，一份套餐可以享受到三大顶尖编程工具协同高效配合，感兴趣的可以看一下往期文章👇</p>',8)),(0,o.Lk)("p",null,[(0,o.Lk)("a",n,[l[3]||(l[3]=(0,o.eW)("教你在国内用一个套餐同时体验到Claude Code+Codex两大AI编程助手",-1)),(0,o.bF)(e)])]),l[6]||(l[6]=(0,o.Fv)('<p><img src="https://pic3.zhimg.com/v2-06a81e8c0e4de8f42667d40d639dc028_1440w.jpg" alt=""></p><h2 id="最后有话说" tabindex="-1"><a class="header-anchor" href="#最后有话说"><span>最后有话说</span></a></h2><p>这次模型更新给人的一个明显感觉是：</p><p>大模型的竞争，正在从“参数、跑分”转向<strong>细节、体验和工作流适配</strong>。</p><p>你不一定需要“最强的模型”，而是需要一个<strong>更适合你干活的模型</strong>。</p><blockquote><p>最近感觉各厂的模型更新都没有像之前一样频繁开发布会了，仿佛模型更新已经成为了一种日常迭代，都开始卷更全面的Agent了。</p></blockquote><p><strong>最后欢迎在评论区聊聊你的使用场景，你会更倾向于把模型放在哪些场景上呢？</strong></p><hr><p>最后感谢大家能够看到文章的最后，如果你觉得这篇文章对你有启发或者帮助，不妨点个关注，你的支持将是我最大的动力，谢谢！</p><p><img src="https://img.zeker.top/official_account_card.webp" alt=""></p>',10))])}]]),t=JSON.parse('{"path":"/blog/claude/claude-opus-4-6-vs-gpt-5-3-codex.html","title":"Claude Opus 4.6 vs GPT-5.3-Codex，主要更新了什么？有哪些不同？如何使用呢？","lang":"en-US","frontmatter":{"title":"Claude Opus 4.6 vs GPT-5.3-Codex，主要更新了什么？有哪些不同？如何使用呢？","date":"2026-02-06 15:00","description":"Claude Opus 4.6 和 GPT-5.3-Codex 有什么不同？哪些更新值得关注？本文全面解析两大模型在编程、推理、多模态与使用场景上的差异，帮助你快速选对适合自己的 AI 模型。","keywords":"Claude Opus 4.6,GPT-5.3-Codex,Claude vs GPT,Codex模型,Claude最新版本,GPT代码模型,AI模型对比,大模型更新,编程AI对比","sidebarDepth":3,"tags":["ChatGPT","Claude","Claude Code"],"categories":["ChatGPT"]},"git":{},"filePathRelative":"blog/claude/claude-opus-4-6-vs-gpt-5-3-codex.md","excerpt":"\\n<p>快过年了，最近国内AI老热闹了，元宝送红包，千问送奶茶，火药味十足，运营更是一套一套的，再看看国外，人家直接双双上模型，给新年打了一手双响炮。</p>\\n<p><img src=\\"https://picx.zhimg.com/v2-3afa54767ca2036449bdd223697f4301_1440w.jpg\\" alt=\\"\\"></p>\\n<p>Anthropic 刚把 <strong>Claude Opus 4.6</strong> 端上来，\\nOpenAI 转头就甩出 <strong>GPT-5.3-Codex</strong>，而且 Codex 不是“PPT 发布”，在 App、CLI、IDE 插件里已经能直接用。</p>\\n<p>更关键的是，这两次更新都不是那种</p>\\n<blockquote>\\n<p>“参数 +1%，大家散了吧”</p>\\n</blockquote>\\n<p>而是<strong>路线非常清晰的强化</strong>：</p>\\n<ul>\\n<li>\\n<p>Claude 继续往「<strong>通用智能、长上下文、复杂思考</strong>」走</p>\\n</li>\\n<li>\\n<p>Codex 则彻底站在「<strong>代码、工程、智能体执行力</strong>」这一边</p>\\n</li>\\n</ul>\\n<p>如果你平时：</p>\\n<ul>\\n<li>要写代码</li>\\n<li>要写文档</li>\\n<li>要做分析</li>\\n<li>或者已经在用 Agent 搭工作流</li>\\n</ul>\\n<p>那这次更新，<strong>大概率会影响你接下来怎么用模型</strong>。</p>\\n<p>所以问题来了：\\n<strong>Claude Opus 4.6 和 GPT-5.3-Codex，到底各自升级了什么？又有什么本质不同？</strong></p>\\n<blockquote>\\n<p>以下均为官方数据</p>\\n<p>👉<strong>文末附带获取方法</strong></p>\\n</blockquote>\\n"}')}}]);